# Call and Return Handling Implementation Plan

## Overview

Implement complete CALL and RETURN instruction lowering for RISC-V 32-bit, with comprehensive testing at each step. This plan emphasizes incremental implementation with `assert_asm` tests to verify correctness at every stage.

**Critical Requirements**:

- Multi-return support from the beginning (not an afterthought)
- Comprehensive testing with `assert_asm` for each small piece
- Handle both register arguments (a0-a7) and stack arguments (>8 args)
- Proper caller-saved register preservation
- Return area mechanism for multi-return

## Current State

**What Exists**:

- ✅ Frame layout computation (`backend/frame.rs`)
- ✅ ABI module with `compute_abi_info()` (`backend/abi.rs`)
- ✅ Prologue/epilogue generation (`backend/abi.rs`)
- ✅ Register allocation and spill/reload planning
- ✅ Lowering infrastructure (`backend/lower/mod.rs`)
- ✅ Most instruction lowering (arithmetic, comparisons, branches, etc.)

**What's Missing**:

- ❌ CALL lowering (`backend/lower/call.rs` - just a panic stub)
- ❌ RETURN lowering (`backend/lower/return_.rs` - minimal implementation)
- ❌ Function parameter loading (incoming args from registers/stack)
- ❌ ABI helper functions (`compute_arg_locs()`, `compute_ret_locs()`)
- ❌ Multi-return return area mechanism
- ❌ Stack argument passing (outgoing and incoming)

## Architecture

### Call Flow

**Caller Side**:

1. Prepare arguments (registers a0-a7 + stack)
2. Preserve caller-saved registers (spill live values)
3. Allocate return area (if multi-return)
4. Pass return area pointer (if multi-return)
5. Emit call instruction (`jal` or `jalr`)
6. Read return values (registers a0-a1 + return area)
7. Restore caller-saved registers

**Callee Side**:

1. Receive arguments (registers a0-a7 + stack)
2. Load function parameters into allocated registers
3. Execute function body
4. Prepare return values (move to a0-a1, store to return area)
5. Emit return instruction

### Return Area Mechanism (Multi-Return)

When a function returns >2 values:

- **Caller**: Allocates return area in outgoing args area, passes pointer in a0
- **Callee**: Receives return area pointer in a0, stores excess returns (values 3+) to return area
- **Caller**: Reads first 2 returns from a0-a1, reads remaining from return area

**Important**: The return area pointer is passed as the **first argument**, shifting all other arguments by one position.

## Implementation Phases

### Phase 1: ABI Helper Functions

**File**: `backend/abi.rs`

**Purpose**: Add helper functions to compute argument and return value locations.

#### 1.1 Add `ArgLoc` and `RetLoc` Types

```rust
/// Location of a function argument
#[derive(Debug, Clone, Copy)]
pub enum ArgLoc {
    /// Argument passed in a register (a0-a7)
    Register(Gpr),
    /// Argument passed on the stack at given offset from SP
    Stack { offset: i32 },
}

/// Location of a return value
#[derive(Debug, Clone, Copy)]
pub enum RetLoc {
    /// Return value in a register (a0-a1)
    Register(Gpr),
    /// Return value in return area at given offset
    ReturnArea { offset: i32 },
}
```

#### 1.2 Implement `compute_arg_locs()`

```rust
/// Compute argument locations for a function signature.
///
/// Returns a vector of ArgLoc, one per argument.
pub fn compute_arg_locs(num_args: usize, has_return_area: bool) -> Vec<ArgLoc> {
    let mut locs = Vec::new();

    // If multi-return, first arg is return area pointer (in a0)
    // This shifts all other args by one register
    let reg_offset = if has_return_area { 1 } else { 0 };

    for i in 0..num_args {
        if i + reg_offset < 8 {
            // In register: a0-a7 (accounting for return area pointer)
            let reg_num = (i + reg_offset) as u8;
            locs.push(ArgLoc::Register(reg_num_to_gpr(reg_num)));
        } else {
            // On stack: offset from caller's SP
            let stack_idx = i + reg_offset - 8;
            let offset = (stack_idx * 4) as i32; // Each arg is 4 bytes
            locs.push(ArgLoc::Stack { offset });
        }
    }

    locs
}
```

**Tests**: `backend/tests/abi_tests.rs`

```rust
#[test]
fn test_compute_arg_locs_simple() {
    let locs = compute_arg_locs(3, false);
    assert_eq!(locs.len(), 3);
    assert_eq!(locs[0], ArgLoc::Register(Gpr::A0));
    assert_eq!(locs[1], ArgLoc::Register(Gpr::A1));
    assert_eq!(locs[2], ArgLoc::Register(Gpr::A2));
}

#[test]
fn test_compute_arg_locs_with_stack() {
    let locs = compute_arg_locs(10, false);
    assert_eq!(locs.len(), 10);
    assert_eq!(locs[0], ArgLoc::Register(Gpr::A0));
    // ... first 8 in registers ...
    assert_eq!(locs[8], ArgLoc::Stack { offset: 0 });
    assert_eq!(locs[9], ArgLoc::Stack { offset: 4 });
}

#[test]
fn test_compute_arg_locs_with_return_area() {
    // Multi-return: first arg is return area pointer in a0
    // Real args start at a1
    let locs = compute_arg_locs(3, true);
    assert_eq!(locs.len(), 3);
    assert_eq!(locs[0], ArgLoc::Register(Gpr::A0)); // Return area pointer
    assert_eq!(locs[1], ArgLoc::Register(Gpr::A1)); // First real arg
    assert_eq!(locs[2], ArgLoc::Register(Gpr::A2)); // Second real arg
}
```

#### 1.3 Implement `compute_ret_locs()`

```rust
/// Compute return value locations for a function signature.
///
/// Returns a vector of RetLoc, one per return value.
pub fn compute_ret_locs(num_rets: usize) -> Vec<RetLoc> {
    let mut locs = Vec::new();

    for i in 0..num_rets {
        if i < 2 {
            // First 2 returns in registers a0-a1
            let reg = if i == 0 { Gpr::A0 } else { Gpr::A1 };
            locs.push(RetLoc::Register(reg));
        } else {
            // Excess returns in return area
            let offset = ((i - 2) * 4) as i32; // Each ret is 4 bytes
            locs.push(RetLoc::ReturnArea { offset });
        }
    }

    locs
}
```

**Tests**:

```rust
#[test]
fn test_compute_ret_locs_simple() {
    let locs = compute_ret_locs(1);
    assert_eq!(locs.len(), 1);
    assert_eq!(locs[0], RetLoc::Register(Gpr::A0));
}

#[test]
fn test_compute_ret_locs_two_regs() {
    let locs = compute_ret_locs(2);
    assert_eq!(locs.len(), 2);
    assert_eq!(locs[0], RetLoc::Register(Gpr::A0));
    assert_eq!(locs[1], RetLoc::Register(Gpr::A1));
}

#[test]
fn test_compute_ret_locs_multi_return() {
    let locs = compute_ret_locs(5);
    assert_eq!(locs.len(), 5);
    assert_eq!(locs[0], RetLoc::Register(Gpr::A0));
    assert_eq!(locs[1], RetLoc::Register(Gpr::A1));
    assert_eq!(locs[2], RetLoc::ReturnArea { offset: 0 });
    assert_eq!(locs[3], RetLoc::ReturnArea { offset: 4 });
    assert_eq!(locs[4], RetLoc::ReturnArea { offset: 8 });
}
```

### Phase 2: Function Parameter Loading

**File**: `backend/lower/mod.rs` (add to `lower_function()`)

**Purpose**: Load function parameters from argument registers and stack into their allocated registers/spill slots.

#### 2.1 Add Parameter Loading to Prologue

After prologue frame setup, before clobber save, load incoming parameters:

```rust
// In lower_function(), after gen_prologue_frame_setup:
// Load function parameters from argument registers/stack
self.load_function_parameters();
```

#### 2.2 Implement `load_function_parameters()`

```rust
fn load_function_parameters(&mut self) {
    let entry_block = &self.function.blocks[0];
    let num_params = entry_block.params.len();

    if num_params == 0 {
        return;
    }

    // Compute argument locations
    let callee_abi = Abi::compute_abi_info(
        num_params,
        self.function.signature.returns.len(),
        true, // enable_multi_ret
    );
    let has_return_area = callee_abi.uses_return_area;
    let arg_locs = compute_arg_locs(num_params, has_return_area);

    // Load each parameter
    for (param_idx, param_value) in entry_block.params.iter().enumerate() {
        let arg_loc = &arg_locs[param_idx];

        // Get where this parameter should be stored (from register allocation)
        if let Some(target_reg) = self.allocation.value_to_reg.get(param_value) {
            // Parameter goes to a register
            match arg_loc {
                ArgLoc::Register(src_reg) => {
                    // Copy from argument register to allocated register
                    if *src_reg != *target_reg {
                        self.inst_buffer_mut().push_add(*target_reg, *src_reg, Gpr::Zero);
                    }
                }
                ArgLoc::Stack { offset } => {
                    // Load from stack (caller's frame, at positive offset from SP)
                    // Stack args are at SP + offset (before our frame setup)
                    // But we've already adjusted SP, so we need to account for that
                    let actual_offset = *offset + self.frame_layout.setup_area_size as i32;
                    self.inst_buffer_mut().push_lw(*target_reg, Gpr::Sp, actual_offset);
                }
            }
        } else if let Some(slot) = self.allocation.value_to_slot.get(param_value) {
            // Parameter is spilled - load to temp register, then store to slot
            let temp_reg = Gpr::T0; // Use temporary register
            match arg_loc {
                ArgLoc::Register(src_reg) => {
                    // Copy from argument register to temp
                    self.inst_buffer_mut().push_add(temp_reg, *src_reg, Gpr::Zero);
                }
                ArgLoc::Stack { offset } => {
                    // Load from stack to temp
                    let actual_offset = *offset + self.frame_layout.setup_area_size as i32;
                    self.inst_buffer_mut().push_lw(temp_reg, Gpr::Sp, actual_offset);
                }
            }
            // Store temp to spill slot (after SP adjustment in clobber save)
            // Store this for later (after clobber save)
            // For now, store immediately - slots are in fixed_frame_storage
            let slot_offset = (*slot * 4) as i32;
            let base_offset = self.frame_layout.outgoing_args_size as i32;
            let total_offset = base_offset + slot_offset;
            self.inst_buffer_mut().push_sw(Gpr::Sp, temp_reg, total_offset);
        }
    }
}
```

**Tests**: `backend/tests/call_tests.rs`

```rust
#[test]
fn test_load_params_reg_args() {
    // Function with 3 parameters, all in registers
    let func = create_function_with_params(3, 1);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        addi sp, sp, -8
        sw ra, 4(sp)
        sw s0, 0(sp)
        add s0, sp, zero
        # Load params: a0->v0, a1->v1, a2->v2
        add v0_reg, a0, zero
        add v1_reg, a1, zero
        add v2_reg, a2, zero
        # ... rest of function ...
    ");
}

#[test]
fn test_load_params_stack_args() {
    // Function with 10 parameters (8 regs + 2 stack)
    let func = create_function_with_params(10, 1);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        addi sp, sp, -8
        sw ra, 4(sp)
        sw s0, 0(sp)
        add s0, sp, zero
        # Load reg params: a0-a7
        add v0_reg, a0, zero
        # ... a1-a7 ...
        # Load stack params: at SP+0 and SP+4 (before our frame)
        lw v8_reg, 0(sp)  # First stack arg
        lw v9_reg, 4(sp)  # Second stack arg
        # ... rest of function ...
    ");
}
```

### Phase 3: CALL Lowering - Basic Structure

**File**: `backend/lower/call.rs`

**Purpose**: Implement basic call lowering with register arguments only.

#### 3.1 Implement Basic Call (Register Args Only)

```rust
pub fn lower_call(
    lowerer: &mut Lowerer,
    callee: &str,
    args: &[Value],
    results: &[Value],
) {
    // Step 1: Get callee function signature
    let callee_func = lowerer.function.module.get_function(callee)
        .expect("Callee function not found");
    let num_args = args.len();
    let num_rets = results.len();

    // Step 2: Compute ABI info
    let callee_abi = Abi::compute_abi_info(num_args, num_rets, true);

    // Step 3: Prepare arguments (registers only for now)
    // Move args to a0-a7
    for (i, arg_value) in args.iter().enumerate() {
        if i >= 8 {
            panic!("Stack args not yet implemented");
        }

        // Get source register
        let src_reg = lowerer.allocation.value_to_reg.get(arg_value)
            .expect("Argument value not allocated");

        // Get target register (a0-a7)
        let target_reg = match i {
            0 => Gpr::A0,
            1 => Gpr::A1,
            2 => Gpr::A2,
            3 => Gpr::A3,
            4 => Gpr::A4,
            5 => Gpr::A5,
            6 => Gpr::A6,
            7 => Gpr::A7,
            _ => unreachable!(),
        };

        // Copy if different
        if *src_reg != target_reg {
            lowerer.inst_buffer_mut().push_add(target_reg, *src_reg, Gpr::Zero);
        }
    }

    // Step 4: Emit call instruction
    // For now, assume direct call (will need function address resolution)
    lowerer.inst_buffer_mut().emit(Inst::Jal {
        rd: Gpr::Ra,
        imm: 0, // Will be fixed up later with relocation
    });

    // Step 5: Read return values
    for (i, result_value) in results.iter().enumerate() {
        if i >= 2 {
            panic!("Multi-return not yet implemented");
        }

        let target_reg = lowerer.allocation.value_to_reg.get(result_value)
            .expect("Result value not allocated");

        let src_reg = if i == 0 { Gpr::A0 } else { Gpr::A1 };

        if *target_reg != src_reg {
            lowerer.inst_buffer_mut().push_add(*target_reg, src_reg, Gpr::Zero);
        }
    }
}
```

**Tests**:

```rust
#[test]
fn test_call_simple_reg_args() {
    // call %helper(v0, v1) -> v2
    // v0 in t0, v1 in t1, v2 in t2
    let func = create_function_with_call(2, 1);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... prologue ...
        # Prepare args: t0->a0, t1->a1
        add a0, t0, zero
        add a1, t1, zero
        jal ra, helper
        # Read return: a0->t2
        add t2, a0, zero
        # ... epilogue ...
    ");
}
```

### Phase 4: CALL Lowering - Stack Arguments

**File**: `backend/lower/call.rs`

**Purpose**: Add support for stack arguments (>8 args).

#### 4.1 Compute Outgoing Args Size

Before calling, compute maximum outgoing args size needed:

```rust
// In lower_function(), update frame layout computation:
let max_outgoing_args = compute_max_outgoing_args_size(&func);
let frame_layout = compute_frame_layout(
    // ... other args ...
    max_outgoing_args, // outgoing_args_size
    // ...
);
```

#### 4.2 Store Stack Arguments

In `lower_call()`, after preparing register args:

```rust
// Store stack arguments (args[8..])
for (i, arg_value) in args.iter().enumerate().skip(8) {
    // Get source register
    let src_reg = lowerer.allocation.value_to_reg.get(arg_value)
        .expect("Argument value not allocated");

    // Compute stack offset (in outgoing args area)
    let stack_idx = i - 8;
    let offset = (stack_idx * 4) as i32;

    // Store to outgoing args area (at SP + offset)
    lowerer.inst_buffer_mut().push_sw(Gpr::Sp, *src_reg, offset);
}
```

**Tests**:

```rust
#[test]
fn test_call_with_stack_args() {
    // call %helper(v0, ..., v9) -> v10
    // First 8 in regs, last 2 on stack
    let func = create_function_with_call(10, 1);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... prologue ...
        # Prepare reg args: a0-a7
        add a0, v0_reg, zero
        # ... a1-a7 ...
        # Store stack args: v8->SP+0, v9->SP+4
        sw sp, v8_reg, 0
        sw sp, v9_reg, 4
        jal ra, helper
        # Read return: a0->v10_reg
        add v10_reg, a0, zero
        # ... epilogue ...
    ");
}
```

### Phase 5: CALL Lowering - Caller-Saved Register Preservation

**File**: `backend/lower/call.rs`

**Purpose**: Spill caller-saved registers that are live across the call.

#### 5.1 Identify Live Caller-Saved Registers

Before the call, identify which caller-saved registers contain live values:

```rust
// Get live values at call site
let call_point = InstPoint { block: block_idx, inst: inst_idx };
let live_values = lowerer.liveness.get_live_values_at(call_point);

// Find caller-saved registers with live values
let mut caller_saved_to_spill = Vec::new();
for value in live_values {
    if let Some(reg) = lowerer.allocation.value_to_reg.get(&value) {
        if is_caller_saved(*reg) {
            caller_saved_to_spill.push((*reg, *value));
        }
    }
}
```

#### 5.2 Spill Before Call, Reload After

```rust
// Spill caller-saved registers before call
for (reg, value) in &caller_saved_to_spill {
    if let Some(slot) = lowerer.spill_reload.get_temp_slot(value) {
        let offset = (slot * 4) as i32;
        let base_offset = lowerer.frame_layout.outgoing_args_size as i32;
        lowerer.inst_buffer_mut().push_sw(Gpr::Sp, *reg, base_offset + offset);
    }
}

// ... emit call ...

// Reload caller-saved registers after call
for (reg, value) in caller_saved_to_spill.iter().rev() {
    if let Some(slot) = lowerer.spill_reload.get_temp_slot(value) {
        let offset = (slot * 4) as i32;
        let base_offset = lowerer.frame_layout.outgoing_args_size as i32;
        lowerer.inst_buffer_mut().push_lw(*reg, Gpr::Sp, base_offset + offset);
    }
}
```

**Tests**:

```rust
#[test]
fn test_call_preserves_caller_saved() {
    // v0 in a0 (caller-saved), call helper, use v0 after
    let func = create_function_with_live_caller_saved();
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... prologue ...
        # v0 is in a0, live across call
        # Spill before call
        sw sp, a0, <temp_slot_offset>
        # Prepare call args
        add a0, t0, zero
        jal ra, helper
        # Reload after call
        lw a0, sp, <temp_slot_offset>
        # ... epilogue ...
    ");
}
```

### Phase 6: RETURN Lowering - Basic Returns

**File**: `backend/lower/return_.rs`

**Purpose**: Implement return value preparation and return instruction.

#### 6.1 Move Return Values to a0-a1

```rust
pub fn lower_return(lowerer: &mut Lowerer, values: &[Value]) {
    // Move return values to a0-a1
    for (i, ret_value) in values.iter().enumerate() {
        if i >= 2 {
            panic!("Multi-return not yet implemented");
        }

        let src_reg = lowerer.allocation.value_to_reg.get(ret_value)
            .expect("Return value not allocated");

        let target_reg = if i == 0 { Gpr::A0 } else { Gpr::A1 };

        if *src_reg != target_reg {
            lowerer.inst_buffer_mut().push_add(target_reg, *src_reg, Gpr::Zero);
        }
    }

    // Epilogue is already generated in lower_function()
    // Just emit return instruction
    lowerer.inst_buffer_mut().emit(Inst::Jalr {
        rd: Gpr::Zero,
        rs1: Gpr::Ra,
        imm: 0,
    });
}
```

**Tests**:

```rust
#[test]
fn test_return_single_value() {
    // return v0 (v0 in t0)
    let func = create_function_with_return(1);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... function body ...
        # Move return value: t0->a0
        add a0, t0, zero
        # Epilogue (already generated)
        lw ra, 4(sp)
        lw s0, 0(sp)
        addi sp, sp, 8
        jalr zero, ra, 0
    ");
}

#[test]
fn test_return_two_values() {
    // return v0, v1 (v0 in t0, v1 in t1)
    let func = create_function_with_return(2);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... function body ...
        # Move return values: t0->a0, t1->a1
        add a0, t0, zero
        add a1, t1, zero
        # Epilogue
        jalr zero, ra, 0
    ");
}
```

### Phase 7: Multi-Return - Return Area Mechanism

**File**: `backend/lower/call.rs` and `backend/lower/return_.rs`

**Purpose**: Implement multi-return using return area mechanism.

#### 7.1 Caller: Allocate Return Area

In `lower_call()`, before preparing arguments:

```rust
// Check if multi-return needed
let callee_abi = Abi::compute_abi_info(num_args, num_rets, true);
if callee_abi.uses_return_area {
    // Allocate return area in outgoing args area
    // Return area is at SP + return_area_offset
    let return_area_offset = callee_abi.stack_args_size as i32;

    // Pass return area pointer as first argument (in a0)
    // But we need to save current a0 if it's used as an argument
    // For now, assume we compute return_area_offset and pass it
    // Actually, we need to pass SP + return_area_offset

    // Load SP + return_area_offset into a0
    // Use temporary register to compute address
    lowerer.inst_buffer_mut().push_addi(Gpr::T0, Gpr::Sp, return_area_offset);
    lowerer.inst_buffer_mut().push_add(Gpr::A0, Gpr::T0, Gpr::Zero);

    // Shift all other arguments by one register
    // Original arg[0] goes to a1, arg[1] to a2, etc.
}
```

#### 7.2 Callee: Store to Return Area

In `lower_return()`, after moving register returns:

```rust
// Store excess returns to return area
for (i, ret_value) in values.iter().enumerate().skip(2) {
    let src_reg = lowerer.allocation.value_to_reg.get(ret_value)
        .expect("Return value not allocated");

    // Return area pointer is in a0 (but we've already moved first return there!)
    // Actually, we need to save return area pointer before moving returns
    // Save a0 (return area pointer) to a temporary register first

    // For now, assume we have return_area_ptr available
    let return_area_offset = ((i - 2) * 4) as i32;

    // Store to return area
    // We need the return area pointer - it was passed in a0
    // But we need it before we overwrite a0 with first return
    // Solution: Save return area pointer at function entry
}
```

**Problem**: Return area pointer is passed in a0, but we also need a0 for first return. Solution: Save return area pointer at function entry.

#### 7.3 Callee: Save Return Area Pointer at Entry

In `load_function_parameters()`:

```rust
// If multi-return, save return area pointer (passed in a0)
if has_return_area {
    // Save a0 (return area pointer) to a callee-saved register or stack slot
    // Use s1 (callee-saved) temporarily
    lowerer.inst_buffer_mut().push_add(Gpr::S1, Gpr::A0, Gpr::Zero);
    // Mark s1 as used (will be saved in prologue)
}
```

#### 7.4 Callee: Use Return Area Pointer

In `lower_return()`:

```rust
// Store excess returns to return area
if values.len() > 2 {
    // Return area pointer is in s1 (saved at entry)
    for (i, ret_value) in values.iter().enumerate().skip(2) {
        let src_reg = lowerer.allocation.value_to_reg.get(ret_value)
            .expect("Return value not allocated");

        let offset = ((i - 2) * 4) as i32;
        lowerer.inst_buffer_mut().push_sw(Gpr::S1, *src_reg, offset);
    }
}
```

#### 7.5 Caller: Read Return Area

In `lower_call()`, after reading register returns:

```rust
// Read excess returns from return area
if num_rets > 2 {
    // Return area is at SP + return_area_offset
    let return_area_offset = callee_abi.stack_args_size as i32;

    for (i, result_value) in results.iter().enumerate().skip(2) {
        let target_reg = lowerer.allocation.value_to_reg.get(result_value)
            .expect("Result value not allocated");

        let offset = ((i - 2) * 4) as i32;
        let total_offset = return_area_offset + offset;
        lowerer.inst_buffer_mut().push_lw(*target_reg, Gpr::Sp, total_offset);
    }
}
```

**Tests**:

```rust
#[test]
fn test_multi_return_three_values() {
    // Function returns 3 values
    let func = create_function_with_multi_return(3);
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... prologue ...
        # Save return area pointer (in a0) to s1
        add s1, a0, zero
        # Load params (shifted: a1->v0, a2->v1, etc.)
        add v0_reg, a1, zero
        # ... function body ...
        # Prepare returns: v0->a0, v1->a1
        add a0, v0_reg, zero
        add a1, v1_reg, zero
        # Store excess return: v2->return_area[0]
        sw s1, v2_reg, 0
        # Epilogue
        jalr zero, ra, 0
    ");
}

#[test]
fn test_call_multi_return() {
    // Call function that returns 3 values
    let func = create_call_with_multi_return();
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # ... prologue ...
        # Allocate return area and pass pointer
        addi t0, sp, <return_area_offset>
        add a0, t0, zero
        # Prepare other args: v0->a1
        add a1, v0_reg, zero
        jal ra, callee
        # Read register returns: a0->v1, a1->v2
        add v1_reg, a0, zero
        add v2_reg, a1, zero
        # Read stack return: return_area[0]->v3
        lw v3_reg, sp, <return_area_offset>
        # ... epilogue ...
    ");
}
```

### Phase 8: Integration and Edge Cases

#### 8.1 Function Address Resolution

For direct calls, need to resolve function addresses. This may require:

- Function address table
- Relocation entries
- Or assume functions are at fixed offsets

**For now**: Use placeholder addresses, add relocations.

#### 8.2 Indirect Calls

Support `jalr` for indirect calls (function pointer in register).

#### 8.3 Edge Cases

- Zero arguments
- Zero returns
- All stack arguments (>8 args, no register args)
- All stack returns (>2 returns, no register returns)
- Large return area (>8 words)
- Nested calls with multi-return

**Tests for Edge Cases**:

```rust
#[test]
fn test_call_zero_args() {
    // call %helper() -> v0
}

#[test]
fn test_call_zero_returns() {
    // call %helper(v0)
}

#[test]
fn test_call_all_stack_args() {
    // call %helper(v0, ..., v15) - all 16 args on stack
}

#[test]
fn test_return_all_stack() {
    // return v0, ..., v15 - all 16 returns on stack
}

#[test]
fn test_nested_multi_return() {
    // outer() calls middle() calls inner()
    // All return multiple values
}
```

## Testing Strategy

### Unit Tests with `assert_asm`

Each phase should have unit tests that verify the exact instruction sequence using `assert_asm`:

```rust
#[test]
fn test_specific_feature() {
    let func = create_test_function();
    let inst_buffer = lower_function(func);

    inst_buffer.assert_asm("
        # Exact instruction sequence expected
        addi sp, sp, -8
        sw ra, 4(sp)
        # ... more instructions ...
    ");
}
```

### Integration Tests

Use existing `expect_ir_syscall` helper to test full execution:

```rust
#[test]
fn test_call_integration() {
    let ir = r#"
    module {
    entry: %bootstrap
    function %bootstrap() -> i32 {
        call %helper() -> v0
        syscall 0(v0)
        halt
    }
    function %helper() -> i32 {
        v0 = iconst 42
        return v0
    }
    }"#;

    expect_ir_syscall(ir, 0, &[42]);
}
```

### Test Coverage

- ✅ 0-8 arguments (all in registers)
- ✅ 9+ arguments (some on stack)
- ✅ 0-2 returns (all in registers)
- ✅ 3+ returns (multi-return)
- ✅ Caller-saved register preservation
- ✅ Stack argument passing
- ✅ Return area mechanism
- ✅ Nested calls
- ✅ Edge cases (zero args, zero returns, all stack, etc.)

## Implementation Order

1. **Phase 1**: ABI helper functions (`compute_arg_locs`, `compute_ret_locs`)
2. **Phase 2**: Function parameter loading
3. **Phase 3**: Basic CALL (register args only)
4. **Phase 6**: Basic RETURN (register returns only)
5. **Phase 4**: CALL with stack arguments
6. **Phase 5**: Caller-saved register preservation
7. **Phase 7**: Multi-return mechanism
8. **Phase 8**: Integration and edge cases

## Success Criteria

1. All existing `call_tests.rs` tests pass
2. All new unit tests with `assert_asm` pass
3. Multi-return works correctly (>2 returns)
4. Stack arguments work correctly (>8 args)
5. Caller-saved registers are preserved
6. Function parameters load correctly (registers and stack)
7. Return values are handled correctly (registers and return area)
8. No regressions in other tests

## Reference

- **RISC-V ABI**: `docs/riscv32-abi.md`
- **Cranelift RV64**: `/Users/yona/dev/photomancer/wasmtime/cranelift/codegen/src/isa/riscv64`
- **Existing Tests**: `backend/tests/call_tests.rs`
