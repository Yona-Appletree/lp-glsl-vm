# Frame Layout, Liveness, Register Allocation, and Phi Node Handling

## Overview

This plan addresses the remaining TODOs in the backend lowering implementation:
1. Frame layout computation based on actual register usage
2. Liveness analysis for proper register allocation
3. Register allocation with spilling support
4. Phi node handling at block boundaries
5. Large constant handling for syscall numbers

The implementation follows Cranelift's architecture with separate passes for liveness analysis, register allocation, spill/reload planning, and instruction lowering.

## Architecture

```
┌─────────────────────────────────────────┐
│  Function IR (with values)              │
└─────────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│  1. Liveness Analysis (liveness.rs)     │
│     - Compute live ranges               │
│     - Build live sets per instruction  │
│     - Handle block parameters           │
└─────────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│  2. Register Allocation (regalloc.rs)  │
│     - Linear scan allocation           │
│     - Assign registers/spill slots     │
│     - Track callee-saved usage         │
└─────────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│  3. Spill/Reload Planning               │
│     (spill_reload.rs)                   │
│     - Insert spills after defs         │
│     - Insert reloads before uses       │
│     - Handle call sites                │
└─────────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│  4. Frame Layout Computation            │
│     (frame.rs)                          │
│     - Use callee-saved from allocation │
│     - Compute spill slot offsets       │
│     - Compute total frame size          │
└─────────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────────┐
│  5. Instruction Lowering (lower.rs)     │
│     - Use pre-computed allocation      │
│     - Emit spill/reload ops            │
│     - Handle phi nodes                 │
│     - No allocation decisions           │
└─────────────────────────────────────────┘
```

## Module Structure

### 1. `liveness.rs` - Liveness Analysis

**Purpose**: Compute which values are live at each point in the function.

**Key Types**:
```rust
/// Instruction point (block index, instruction index)
#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct InstPoint {
    pub block: usize,
    pub inst: usize,
}

/// Live range for a value (from definition to last use)
#[derive(Clone, Debug)]
pub struct LiveRange {
    /// Point where value is defined
    pub def: InstPoint,
    /// Point where value is last used
    pub last_use: InstPoint,
    /// All points where value is used
    pub uses: Vec<InstPoint>,
}

/// Liveness information for a function
pub struct LivenessInfo {
    /// Live range for each value
    pub live_ranges: BTreeMap<Value, LiveRange>,
    /// Set of live values at each instruction point
    pub live_sets: BTreeMap<InstPoint, BTreeSet<Value>>,
    /// Values defined at each instruction point
    pub defs: BTreeMap<InstPoint, Value>,
    /// Values used at each instruction point
    pub uses: BTreeMap<InstPoint, Vec<Value>>,
    /// Block parameters (phi-like values) - map from (block_idx, param_idx) to Value
    pub block_params: BTreeMap<(usize, usize), Value>,
}
```

**Key Functions**:
```rust
/// Compute liveness for all values in a function
pub fn compute_liveness(func: &Function) -> LivenessInfo {
    // 1. Forward pass: collect all definitions
    // 2. Backward pass: compute last uses and live ranges
    // 3. Build live sets for each instruction point
    // 4. Handle block parameters (phi-like values)
    // 5. Handle values live across blocks
}
```

**Algorithm**:
1. **Forward Pass**: Collect all value definitions
   - Iterate through all blocks and instructions
   - Record where each value is defined
   - Handle block parameters (defined at block entry)

2. **Backward Pass**: Compute last uses
   - Start from return statements and block exits
   - Propagate liveness backward through instructions
   - Track last use of each value

3. **Live Range Construction**:
   - For each value: `[def, last_use]` is the live range
   - Collect all use points

4. **Block Parameter Handling**:
   - Block parameters are "defined" at block entry
   - They represent values from predecessor blocks
   - Track which predecessor provides which value

**Edge Cases**:
- Values used before defined (block parameters)
- Values defined but never used
- Values used in multiple blocks
- Values live across calls
- Values used in return statements
- Block parameters with multiple predecessors

**Tests**:
- `test_liveness_simple_sequential` - Sequential values
- `test_liveness_block_parameters` - Block params (phi-like)
- `test_liveness_unused_values` - Values defined but not used
- `test_liveness_multiple_uses` - Values used multiple times
- `test_liveness_across_calls` - Values live across function calls
- `test_liveness_loop` - Values live in loops
- `test_liveness_conditional` - Values in conditional branches

### 2. `regalloc.rs` - Register Allocation

**Purpose**: Assign registers to values using linear scan allocation.

**Key Types**:
```rust
/// Register allocation result
pub struct RegisterAllocation {
    /// Value -> Register mapping (for values in registers)
    pub value_to_reg: BTreeMap<Value, Gpr>,
    /// Value -> Spill slot mapping (for spilled values)
    pub value_to_slot: BTreeMap<Value, u32>,
    /// Register -> Value mapping (reverse lookup, for active intervals)
    pub reg_to_value: BTreeMap<Gpr, Value>,
    /// Which callee-saved registers are used
    pub used_callee_saved: Vec<Gpr>,
    /// Number of spill slots needed
    pub spill_slot_count: usize,
}

/// Active interval during linear scan
struct ActiveInterval {
    value: Value,
    reg: Gpr,
    live_range: LiveRange,
}

/// Linear scan register allocator
pub struct LinearScanAllocator {
    /// Available registers (caller-saved first, then callee-saved)
    available_regs: Vec<Gpr>,
    /// Currently active intervals
    active: Vec<ActiveInterval>,
    /// Spill slot counter
    next_spill_slot: u32,
    /// Callee-saved registers used
    used_callee_saved: BTreeSet<Gpr>,
}
```

**Key Functions**:
```rust
/// Allocate registers for a function
pub fn allocate_registers(
    func: &Function,
    liveness: &LivenessInfo,
) -> RegisterAllocation {
    // 1. Sort values by definition point
    // 2. Linear scan: allocate registers, spill when needed
    // 3. Track callee-saved register usage
    // 4. Assign spill slots
}
```

**Allocation Strategy** (Linear Scan):
1. **Sort values by definition point** (earliest first)
2. **For each value in order**:
   - Expire intervals that end before this value's definition
   - Try to allocate a caller-saved register (a0-a7, t0-t6)
   - If none available, try callee-saved register (s0-s11)
   - If still none available, spill the value with furthest next use
3. **Prefer caller-saved registers** (don't need saving)
4. **Use callee-saved registers** when needed (must be saved in prologue)
5. **Spill when all registers are in use** (assign spill slot)

**Register Ordering** (from Cranelift):
- **Caller-saved**: a0-a7 (x10-x17), t0-t6 (x5-x7, x28-x31)
- **Callee-saved**: s0-s11 (x8-x9, x18-x27)
- **Special**: ra (x1), sp (x2), fp (x8/s0), zero (x0)

**Spill Decision**:
- When all registers are in use, choose value with furthest next use
- Assign spill slot (4 bytes per slot for RV32)
- Track spill slot count for frame layout

**Edge Cases**:
- All registers in use (must spill)
- Values with very long live ranges
- Values used immediately after definition
- Values only used in return statements
- Block parameters (already in argument registers)
- Function return values (must be in a0-a7)
- Call arguments (must be in a0-a7)
- Values live across multiple calls

**Tests**:
- `test_allocate_simple` - Simple sequential allocation
- `test_allocate_many_values` - More values than registers
- `test_allocate_spill` - Verify spilling works
- `test_allocate_callee_saved` - Callee-saved register usage
- `test_allocate_block_params` - Block parameters
- `test_allocate_call_args` - Function call arguments
- `test_allocate_return_values` - Return values
- `test_allocate_long_live_ranges` - Values with long live ranges
- `test_allocate_interference` - Interfering values get different registers

### 3. `spill_reload.rs` - Spill/Reload Insertion

**Purpose**: Insert explicit spill and reload instructions at the right points.

**Key Types**:
```rust
/// Spill or reload operation
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum SpillReloadOp {
    /// Spill a value from register to stack
    Spill { value: Value, reg: Gpr, slot: u32 },
    /// Reload a value from stack to register
    Reload { value: Value, reg: Gpr, slot: u32 },
}

/// Spill/reload insertion plan
pub struct SpillReloadPlan {
    /// Operations to insert before each instruction
    pub before: BTreeMap<InstPoint, Vec<SpillReloadOp>>,
    /// Operations to insert after each instruction
    pub after: BTreeMap<InstPoint, Vec<SpillReloadOp>>,
    /// Operations to insert at block boundaries (before block entry)
    pub block_boundary: BTreeMap<usize, Vec<SpillReloadOp>>,
    /// Maximum temporary spill slots needed (for frame layout)
    pub max_temp_spill_slots: usize,
}
```

**Key Functions**:
```rust
/// Create spill/reload plan for a function
pub fn create_spill_reload_plan(
    func: &Function,
    allocation: &RegisterAllocation,
    liveness: &LivenessInfo,
) -> SpillReloadPlan {
    // For each spilled value:
    // 1. Spill after definition (if value is live across calls/blocks)
    // 2. Reload before use (if value is not in register)
    // 3. Handle call sites: spill caller-saved before call, reload after
    // 4. Handle block boundaries: reload spilled values used in block
}
```

**Insertion Strategy**:
1. **After Definition**: Spill immediately if value is spilled and will be used later
2. **Before Use**: Reload before use if value is spilled
3. **Before Call**: Spill all live caller-saved values (they'll be clobbered)
4. **After Call**: Reload spilled values that are still live
5. **Block Boundaries**: Reload spilled values used in successor blocks

**Call Site Handling** (from Cranelift):
- Before call: Spill all live caller-saved registers (they'll be clobbered)
- After call: Reload spilled values that are still live
- Use temporary spill slots if needed (track max needed)

**Block Boundary Handling**:
- When entering a block, reload spilled values used in that block
- Handle phi nodes: reload spilled values that feed into phi nodes

**Edge Cases**:
- Values spilled but never reloaded (dead code)
- Values reloaded multiple times
- Values spilled multiple times
- Call sites with no live values
- Block parameters that are spilled
- Return values that are spilled
- Multiple reloads of same value in same block

**Tests**:
- `test_spill_after_def` - Spill after definition
- `test_reload_before_use` - Reload before use
- `test_call_site_spill_reload` - Call site handling
- `test_block_boundary_reload` - Block boundary handling
- `test_multiple_reloads` - Multiple reloads of same value
- `test_dead_spilled_value` - Spilled value never reloaded
- `test_spilled_return_value` - Spilled return value

### 4. Frame Layout Integration

**Current Issue**: Frame layout is computed with empty clobbered registers list.

**Solution**: Use register allocation results to compute frame layout.

**Changes to `frame.rs`**:
- No changes needed - `compute_frame_layout` already accepts `clobbered_callee_saves`
- Use `allocation.used_callee_saved` from register allocation
- Use `allocation.spill_slot_count + spill_reload.max_temp_spill_slots` for spill slots

**Changes to `lower/mod.rs`**:
- Remove frame layout computation from `Lowerer::new()`
- Compute frame layout after register allocation
- Pass frame layout to `Lowerer` constructor

**Integration Point**:
```rust
// In backend/mod.rs or compile function:
let liveness = compute_liveness(&func);
let allocation = allocate_registers(&func, &liveness);
let spill_reload = create_spill_reload_plan(&func, &allocation, &liveness);

let total_spill_slots = allocation.spill_slot_count + spill_reload.max_temp_spill_slots;
let frame_layout = compute_frame_layout(
    &allocation.used_callee_saved,
    function_calls,
    incoming_args_size,
    tail_args_size,
    total_spill_slots as u32, // stackslots_size
    0, // fixed_frame_storage_size
    outgoing_args_size,
    false, // preserve_frame_pointers
);

let lowerer = Lowerer::new(func, allocation, spill_reload, frame_layout);
```

### 5. Phi Node Handling

**Current Issue**: Block parameters (phi nodes) aren't handled.

**Solution**: Handle phi nodes during lowering by copying values from predecessor blocks.

**Key Insight**: In SSA form, block parameters represent values from predecessor blocks. When entering a block, we need to copy values from the predecessor's corresponding values into the block parameter registers.

**Implementation in `lower/mod.rs`**:

```rust
fn lower_block(&mut self, block_idx: usize, block: &Block) {
    // Record block start
    let block_start = self.inst_buffer.instruction_count();
    self.block_addresses[block_idx] = block_start;

    // Handle block parameters (phi nodes)
    for (param_idx, param_value) in block.params.iter().enumerate() {
        // Get register for this parameter
        let param_reg = self.allocation.value_to_reg.get(param_value)
            .copied()
            .expect("Block parameter must have register allocation");
        
        // Find predecessor blocks
        let predecessors = self.find_predecessors(block_idx);
        
        // For now, handle single predecessor case
        // TODO: Handle multiple predecessors (parallel copy)
        if predecessors.len() == 1 {
            let pred_idx = predecessors[0];
            // Find which value from predecessor feeds this parameter
            // This requires tracking phi node sources (future enhancement)
            // For now, assume parameter value is already correct
        } else {
            // Multiple predecessors: need parallel copy
            // This is complex and can be handled later
            // For now, assume values are already in correct registers
        }
    }

    // Lower all instructions in the block
    for inst in &block.insts {
        self.lower_inst(inst);
    }
}
```

**Simplified Approach** (for initial implementation):
- If block has single predecessor: copy values directly
- If multiple predecessors: assume values are already in correct registers (from branch lowering)
- This works if we handle phi nodes at branch sites (copy values before branching)

**Future Enhancement**:
- Track phi node sources explicitly
- Implement parallel copy for multiple predecessors
- Handle spilled phi node values

**Tests**:
- `test_phi_single_predecessor` - Phi node with single predecessor
- `test_phi_multiple_predecessors` - Phi node with multiple predecessors
- `test_phi_spilled_value` - Phi node with spilled value

### 6. Large Constant Handling

**Current Issue**: `addi` only supports 12-bit signed immediates (-2048 to 2047).

**Solution**: Use `lui` + `addi` sequence for large constants, similar to `lower_iconst`.

**Changes to `lower/helpers.rs`**:

```rust
pub fn lower_syscall(lowerer: &mut Lowerer, number: i32, args: &[Value]) {
    // Load syscall number into a7
    // Handle large constants using lui + addi
    if number >= -2048 && number <= 2047 {
        // Fits in 12-bit signed immediate
        lowerer.inst_buffer_mut().push_addi(Gpr::A7, Gpr::Zero, number);
    } else {
        // Use lui + addi sequence (same as lower_iconst)
        iconst::lower_iconst_into_reg(lowerer, Gpr::A7, number as i64);
    }
    
    // ... rest of syscall handling
}
```

**Reuse Logic**: Extract constant loading logic from `iconst.rs` into a helper function that can be used by both `lower_iconst` and `lower_syscall`.

**Tests**:
- `test_syscall_small_number` - Syscall number < 2048
- `test_syscall_large_number` - Syscall number > 2047
- `test_syscall_negative_number` - Negative syscall number

## Implementation Order

1. **Liveness Analysis** (`liveness.rs`)
   - Foundation for everything else
   - Can be tested independently
   - No dependencies

2. **Register Allocation** (`regalloc.rs`)
   - Depends on liveness
   - Core allocation logic
   - Spill slot assignment

3. **Spill/Reload Planning** (`spill_reload.rs`)
   - Depends on allocation and liveness
   - Insertion logic
   - Call site handling

4. **Frame Layout Integration**
   - Use allocation results
   - Update `Lowerer::new()` signature
   - Update call sites

5. **Phi Node Handling**
   - Depends on allocation
   - Handle in `lower_block()`
   - Start with single predecessor

6. **Large Constant Handling**
   - Isolated change
   - Reuse iconst logic
   - Update syscall lowering

## File Structure

```
crates/lpc-riscv32/src/backend/
├── mod.rs                    # Public API, integration
├── abi.rs                    # ABI handling (already exists)
├── frame.rs                  # Frame layout (already exists, minor updates)
├── liveness.rs               # NEW: Liveness analysis
├── regalloc.rs               # NEW: Register allocation
├── spill_reload.rs          # NEW: Spill/reload planning
├── lower/
│   ├── mod.rs               # Update: Use pre-computed allocation
│   ├── helpers.rs           # Update: Large constant handling
│   └── ...                  # Other lowering modules
└── tests/
    ├── liveness_tests.rs    # NEW: Liveness tests
    ├── regalloc_tests.rs    # NEW: Register allocation tests
    ├── spill_reload_tests.rs # NEW: Spill/reload tests
    └── ...                  # Existing tests
```

## Integration with Existing Code

**Current `Lowerer` Structure**:
- Currently allocates registers on-the-fly
- Needs to use pre-computed allocation instead

**Changes Required**:
1. Add `allocation: RegisterAllocation` field to `Lowerer`
2. Add `spill_reload: SpillReloadPlan` field to `Lowerer`
3. Update `get_reg_for_value()` to lookup from allocation
4. Add spill/reload instruction emission
5. Handle phi nodes in `lower_block()`

**New `Lowerer` Constructor**:
```rust
impl Lowerer {
    pub fn new(
        function: Function,
        allocation: RegisterAllocation,
        spill_reload: SpillReloadPlan,
        frame_layout: FrameLayout,
        abi: Abi,
    ) -> Self {
        // Initialize with pre-computed allocation
    }
}
```

## Testing Strategy

1. **Unit Tests**: Each module tested independently
   - Liveness analysis tests
   - Register allocation tests
   - Spill/reload planning tests

2. **Integration Tests**: Full compilation pipeline
   - End-to-end tests with register allocation
   - Tests with spilling
   - Tests with phi nodes

3. **Existing Tests**: Update to use new allocation
   - Update `branch_tests.rs` to use new API
   - Update other test files

## Success Criteria

1. Frame layout correctly includes callee-saved registers when used
2. Liveness analysis correctly identifies live values
3. Register allocation assigns registers and spill slots correctly
4. Spill/reload instructions are inserted at correct points
5. Phi nodes are handled for single-predecessor blocks
6. Syscall numbers > 2047 work correctly
7. All existing tests pass with new allocation system

## Reference Implementation

- **Cranelift RV64**: `/Users/yona/dev/photomancer/wasmtime/cranelift/codegen/src/isa/riscv64`
  - `abi.rs`: Frame layout computation, ABI handling
  - `lower.rs`: Instruction lowering (uses pre-computed allocation)
  - Register allocation handled by `regalloc2` crate

- **Old Implementation**: Commit `7ee766e79de146b2d690c2ff73906a57ea35b922`
  - Had liveness, regalloc, spill_reload modules (now deleted)
  - Mixed allocation with lowering (problematic)
  - Can reference structure but not implementation details

## Notes

- This is a significant refactoring that changes the lowering architecture
- Register allocation becomes a separate pass before lowering
- Lowering becomes simpler (just lookup registers and emit instructions)
- Follows Cranelift's proven architecture
- Enables proper spilling and phi node handling

